{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pLsI6Mpf76wm",
   "metadata": {
    "id": "pLsI6Mpf76wm"
   },
   "source": [
    "# HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6982465",
   "metadata": {
    "id": "f6982465"
   },
   "outputs": [],
   "source": [
    "# Name: Seyyid Osman Sevgili    \n",
    "# ID: 504221565"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16488f",
   "metadata": {
    "id": "4d16488f"
   },
   "source": [
    "## PART I - Convolutional Neural Networks [12 pts]\n",
    "\n",
    "In this part of assignment, first we will implement convolution operation in 2 dimensions, then we will move to a Deep Learning framework for faster computation via GPUs!\n",
    "\n",
    "In this assignment, we will use the same API as in Assignment 1. You have implemented most of the required layers. You will add Conv2d layer under `DL/CNN.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a681fd",
   "metadata": {
    "id": "d5a681fd"
   },
   "outputs": [],
   "source": [
    "from DL.CNN import Conv2d\n",
    "from DL.checker.checks import *\n",
    "import numpy as np\n",
    "from DL.regularizers import Dropout, MaxPool2d, AveragePool2d, BatchNorm, BatchNorm2d\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a84cc",
   "metadata": {
    "id": "3d8a84cc"
   },
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5e2d3",
   "metadata": {
    "id": "e3b381bf"
   },
   "source": [
    "### Convolutional Layer\n",
    "Implement and call the forward and backward passes for the convolutional layer in conv2d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b381bf",
   "metadata": {
    "id": "e3b381bf"
   },
   "source": [
    "#### Forward Pass  [6 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9704df",
   "metadata": {
    "id": "ac9704df"
   },
   "outputs": [],
   "source": [
    "conv = Conv2d(in_size=1, out_size=1, kernel_size=4, stride=2, padding=1)\n",
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "conv.W = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "conv.b = np.linspace(-0.2, 0.3, num=3)\n",
    "\n",
    "\n",
    "out = conv.forward(x)\n",
    "# difference should be around 2e-8\n",
    "print('Testing conv_forward_naive')\n",
    "relError = rel_error(out, \"CNN_forward\")\n",
    "print(f'difference: ', relError)\n",
    "assert 2.9e-8 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055d6e",
   "metadata": {
    "id": "d1055d6e"
   },
   "source": [
    "#### Backward Pass  [6 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded79c5f",
   "metadata": {
    "id": "ded79c5f"
   },
   "outputs": [],
   "source": [
    "np.random.seed(250)\n",
    "conv = Conv2d(in_size=1, out_size=2, stride=1, padding=1, kernel_size=3)\n",
    "\n",
    "x = np.random.randn(3, 1, 6, 6)\n",
    "conv.W = np.random.randn(2, 1, 3, 3)\n",
    "conv.b = np.random.randn(2,)\n",
    "dout = np.random.randn(3, 2, 6, 6)\n",
    "\n",
    "dx_num = grad_check(lambda _: conv.forward(x), x, dout)\n",
    "dw_num = grad_check(lambda _: conv.forward(x), conv.W, dout)\n",
    "db_num = grad_check(lambda _: conv.forward(x), conv.b, dout)\n",
    "\n",
    "out = conv.forward(x)\n",
    "dx, dw, db = conv.backward(dout)\n",
    "\n",
    "print(f'dx error: {rel_error(dx, dx_num)}')\n",
    "print(f'dw error: {rel_error(dw, dw_num)}')\n",
    "print(f'db error: {rel_error(db, db_num)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b3161",
   "metadata": {
    "id": "755b3161"
   },
   "source": [
    "## PART II - Regularizers and Pooling  [32 pts]\n",
    "\n",
    "You are going to implement regularization techniques widely used until recently in convolutional networks such as **Max Pooling** and **Dropout**\n",
    "\n",
    "Find `Dropout`, `MaxPool2d`, `AveragePool2d`, `BatchNorm` and `BatchNorm2d` classes in **`DL/regularizers.py`** and complete the implementation of `forward` and `backward` methods for both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c018ab5",
   "metadata": {
    "id": "968c48e7"
   },
   "source": [
    "### Dropout layer\n",
    "\n",
    "As we covered in the class, dropout is a well-known regularization technique for preventing overfitting of neural networks. What dropout does is basically zeroing out of some outputs of hidden layers at random. We recommend you to multiply the dropout factor with outputs in forward pass as it is done in common implementations. Recall that this is called **Inverted Dropout**.\n",
    "\n",
    "For more information on dropout, you can check the paper below.\n",
    "\n",
    "**Improving neural networks by preventing co-adaptation of feature detectors**, Hinton et al.\n",
    "https://arxiv.org/pdf/1207.0580.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c48e7",
   "metadata": {
    "id": "968c48e7"
   },
   "source": [
    "#### Forward pass  [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13cab4",
   "metadata": {
    "id": "2e13cab4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(250)\n",
    "\n",
    "x = np.random.randn(500, 2000) + 250\n",
    "for p in [0.3, 0.5, 0.8]:\n",
    "    dropout = Dropout(p=p)\n",
    "    dropout.mode = 'train'\n",
    "    out = dropout.forward(x)\n",
    "    dropout.mode = 'test'\n",
    "    out_test = dropout.forward(x)\n",
    "\n",
    "    print(f'Dropout rate is: {p}')\n",
    "    print(f'Percent of how much of input is zeroed out in training  {(out == 0).mean():.5f}, in testing {(out_test == 0).mean():.5f}')\n",
    "\n",
    "# You can check wheter your implemention is true or not by looking at the percent of outputs set to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa331f",
   "metadata": {
    "id": "30fa331f"
   },
   "source": [
    "#### Backward pass  [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9001b6",
   "metadata": {
    "id": "8f9001b6"
   },
   "outputs": [],
   "source": [
    "dropout = Dropout(p=0.75)\n",
    "np.random.seed(250)\n",
    "x = np.random.randn(12, 12) + 11\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "\n",
    "out = dropout.forward(x,seed=250)\n",
    "dx = dropout.backward(dout)\n",
    "dx_num = grad_check(lambda xx: dropout.forward(xx, seed=250), x, dout)\n",
    "\n",
    "relError = rel_error(dx, dx_num)\n",
    "print(f'Error on dx {relError}')\n",
    "assert 5e-10 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83addef7",
   "metadata": {
    "id": "83addef7"
   },
   "source": [
    "### MaxPool\n",
    "#### Forward Pass  [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fffb38",
   "metadata": {
    "id": "e8fffb38"
   },
   "outputs": [],
   "source": [
    "x_shape = (3, 3, 7, 7)\n",
    "x = np.linspace(-0.2, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "maxPool = MaxPool2d(stride = 2, pool_width = 3, pool_height = 3)\n",
    "out = maxPool.forward(x)\n",
    "\n",
    "relError = rel_error(out, \"maxpool_forward\")\n",
    "print(f'Error: {relError}')\n",
    "assert 1e-6 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8a2a4",
   "metadata": {
    "id": "efa8a2a4"
   },
   "source": [
    "#### Backward pass  [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8acbbea",
   "metadata": {
    "id": "c8acbbea"
   },
   "outputs": [],
   "source": [
    "np.random.seed(250)\n",
    "x = np.random.randn(8, 1, 10, 10)\n",
    "dout = np.random.randn(8, 1, 5, 5)\n",
    "max_pool = MaxPool2d(pool_height=2, pool_width=2, stride=2)\n",
    "dx_num = grad_check(lambda x: max_pool.forward(x), x, dout)\n",
    "\n",
    "out = max_pool.forward(x)\n",
    "dx = max_pool.backward(dout)\n",
    "\n",
    "# Your error should be around 1e-12\n",
    "print('Testing max_pool_backward_naive function:')\n",
    "relError = rel_error(dx, dx_num)\n",
    "print(f'dx error: {relError}')\n",
    "assert 5e-12 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e611bf2",
   "metadata": {
    "id": "7e611bf2"
   },
   "source": [
    "### AveragePool\n",
    "#### Forward Pass  [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af188f7b",
   "metadata": {
    "id": "af188f7b"
   },
   "outputs": [],
   "source": [
    "x_shape = (3, 3, 7, 7)\n",
    "x = np.linspace(-0.2, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "average_pool = AveragePool2d(stride = 2, pool_width = 3, pool_height = 3)\n",
    "out = average_pool.forward(x)\n",
    "\n",
    "relError = rel_error(out, \"averagepool_forward\")\n",
    "print(f'Error: {relError}')\n",
    "assert 2e-7 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69173012",
   "metadata": {
    "id": "69173012"
   },
   "source": [
    "#### Backward Pass  [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97f345",
   "metadata": {
    "id": "bb97f345"
   },
   "outputs": [],
   "source": [
    "np.random.seed(250)\n",
    "x = np.random.randn(8, 1, 10, 10)\n",
    "dout = np.random.randn(8, 1, 5, 5)\n",
    "average_pool = AveragePool2d(pool_height=2, pool_width=2, stride=2)\n",
    "dx_num = grad_check(lambda x: average_pool.forward(x), x, dout)\n",
    "\n",
    "out = average_pool.forward(x)\n",
    "dx = average_pool.backward(dout)\n",
    "\n",
    "# Your error should be around 1e-11\n",
    "print('Testing average_pool_backward_naive function:')\n",
    "relError = rel_error(dx, dx_num)\n",
    "print(f'dx error: {relError}')\n",
    "assert 5e-10 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f054d7",
   "metadata": {
    "id": "03f054d7"
   },
   "source": [
    "### Batch Normalization 1D\n",
    "\n",
    "#### Forward Pass  [3 pts]\n",
    "First read and understand the paper:\n",
    "\n",
    "S. Ioffe, C. Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
    "https://arxiv.org/pdf/1502.03167.pdf\n",
    "\n",
    "Implement the forward and backward passes for the Batch Normalization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5bd07",
   "metadata": {
    "id": "61f5bd07"
   },
   "outputs": [],
   "source": [
    "# You should understand how the gamma and beta parameters affect to the output\n",
    "\n",
    "# An example of a single hidden layer with ReLU activation.\n",
    "np.random.seed(250)\n",
    "N, D1, D2 = 180, 60, 3,\n",
    "X = np.random.randn(N, D1)\n",
    "W1 = np.random.randn(D1, D2)\n",
    "a = np.maximum(0, X.dot(W1))\n",
    "\n",
    "bn1 = BatchNorm(D2)\n",
    "\n",
    "print('Without using batchnorm')\n",
    "print(f'\\t mean of each feature/channel: {a.mean(axis=0)}')\n",
    "print(f'\\t stds of each feature/channel: {a.std(axis=0)}')\n",
    "\n",
    "\n",
    "print('Stats after batch normalization with gamma=1, beta=0')\n",
    "normalized = bn1.forward(a)\n",
    "print(f'\\t mean: {normalized.mean(axis=0)}')\n",
    "print(f'\\t std: {normalized.std(axis=0)}')\n",
    "\n",
    "\n",
    "bn1.gamma = np.array([3.0, 2.0, 1.0])\n",
    "bn1.beta = np.array([4, 2, 5])\n",
    "normalized  = bn1.forward(a)\n",
    "print('Stats after batch normalization with arbitirary parameters')\n",
    "print(f'\\t mean: {normalized.mean(axis=0)}')\n",
    "print(f'\\t std: {normalized.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c249d01",
   "metadata": {
    "id": "1c249d01"
   },
   "source": [
    "#### Backward pass  [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2be41",
   "metadata": {
    "id": "1dc2be41"
   },
   "outputs": [],
   "source": [
    "# Gradient check batchnorm backward pass\n",
    "np.random.seed(250)\n",
    "N, D = 20, 6\n",
    "x = 3 * np.random.randn(N, D) + 9\n",
    "\n",
    "bn1 = BatchNorm(D)\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "fx = lambda x: bn1.forward(x, gamma=gamma, beta=beta)\n",
    "fg = lambda a: bn1.forward(x, gamma=a, beta=beta)\n",
    "fb = lambda b: bn1.forward(x, gamma=gamma, beta=b)\n",
    "\n",
    "dx_num = grad_check(fx, x, dout)\n",
    "da_num = grad_check(fg, gamma.copy(), dout)\n",
    "db_num = grad_check(fb, beta.copy(), dout)\n",
    "\n",
    "bn1.forward(x, gamma=gamma, beta=beta)\n",
    "dx, dgamma, dbeta = bn1.backward(dout)\n",
    "\n",
    "relError = rel_error(dx_num, dx)\n",
    "print(f'dx error: {relError}')\n",
    "assert 1e-7 > relError\n",
    "\n",
    "relError = rel_error(da_num, dgamma)\n",
    "print(f'dgamma error: {relError}')\n",
    "assert 1e-10 > relError\n",
    "\n",
    "relError = rel_error(db_num, dbeta)\n",
    "print(f'dbeta error: {relError}')\n",
    "assert 1e-11 > relError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TiYFrOyMtTfG",
   "metadata": {
    "id": "TiYFrOyMtTfG"
   },
   "source": [
    "### Batch Normalization 2D\n",
    "#### Forward Pass  [2 pts]\n",
    "\n",
    "Implement BatchNorm2d. This computes statistics per-channel over batch as in pytorch-Batchnorm2D. You can take the Pytorch documentation as reference.\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dtxa1K6GtT-m",
   "metadata": {
    "id": "dtxa1K6GtT-m"
   },
   "outputs": [],
   "source": [
    "np.random.seed(250)\n",
    "N, C, H, W = 180, 3, 5, 5  # Batch size, channels, height, width\n",
    "\n",
    "# Generating random data with the correct shape\n",
    "X = np.random.randn(N, C, H, W)\n",
    "\n",
    "W = np.array([2., 3., 1.]).reshape((1,C,1,1))\n",
    "b = np.array([1., 0.5, 3.]).reshape((1,C,1,1))\n",
    "# Reshaping for the linear layer - simulating a linear transformation\n",
    "a = W*X + b\n",
    "\n",
    "# Creating a BatchNorm2d instance for the specified number of channels\n",
    "bn2d = BatchNorm2d(C)\n",
    "\n",
    "print('Without using BatchNorm2d')\n",
    "print(f'\\t mean of each channel: {a.mean(axis=(0,2,3))}')\n",
    "print(f'\\t std of each channel: {a.std(axis=(0,2,3))}')\n",
    "\n",
    "# Using BatchNorm2d with default parameters (gamma=1, beta=0)\n",
    "normalized = bn2d.forward(X)\n",
    "print('\\nStats after BatchNorm2d normalization with gamma=1, beta=0')\n",
    "print(f'\\t mean: {normalized.mean(axis=(0, 2, 3))}')\n",
    "print(f'\\t std: {normalized.std(axis=(0, 2, 3))}')\n",
    "\n",
    "# Changing gamma and beta parameters\n",
    "bn2d.gamma = np.array([3.0, 2.0, 1.0]).reshape((1,C,1,1))\n",
    "bn2d.beta = np.array([4, 2, 5]).reshape((1,C,1,1))\n",
    "normalized = bn2d.forward(X)\n",
    "\n",
    "print('\\nStats after BatchNorm2d normalization with arbitrary parameters')\n",
    "print(f'\\t mean: {normalized.mean(axis=(0, 2, 3))}')\n",
    "print(f'\\t std: {normalized.std(axis=(0, 2, 3))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K-BKhau-n31Q",
   "metadata": {
    "id": "K-BKhau-n31Q"
   },
   "source": [
    "#### Backward pass  [4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Kr9Cvzln4ge",
   "metadata": {
    "id": "2Kr9Cvzln4ge"
   },
   "outputs": [],
   "source": [
    "np.random.seed(250)\n",
    "N, C, H, W = 10, 3, 4, 4  # Batch size, channels, height, width\n",
    "\n",
    "x = 3 * np.random.randn(N, C, H, W) + 7\n",
    "\n",
    "bn2d = BatchNorm2d(C)\n",
    "gamma = np.random.randn(C).reshape((1,C,1,1))\n",
    "beta = np.random.randn(C).reshape((1,C,1,1))\n",
    "dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "# Function to be used for numerical gradient calculation\n",
    "fx = lambda x: bn2d.forward(x, gamma=gamma, beta=beta)\n",
    "fg = lambda g: bn2d.forward(x, gamma=g, beta=beta)\n",
    "fb = lambda b: bn2d.forward(x, gamma=gamma, beta=b)\n",
    "\n",
    "# Gradient check for dx (input)\n",
    "dx_num = grad_check(fx, x, dout)\n",
    "\n",
    "# Gradient check for dgamma (gamma parameter)\n",
    "da_num = grad_check(fg, gamma.copy(), dout)\n",
    "\n",
    "# Gradient check for dbeta (beta parameter)\n",
    "db_num = grad_check(fb, beta.copy(), dout)\n",
    "\n",
    "# Perform the backward pass to get gradients from the BatchNorm2d layer\n",
    "bn2d.forward(x, gamma=gamma, beta=beta)\n",
    "dx, dgamma, dbeta = bn2d.backward(dout)\n",
    "\n",
    "# Calculate relative errors for each gradient\n",
    "rel_error_dx = rel_error(dx_num, dx)\n",
    "print(f'dx error: {rel_error_dx}')\n",
    "assert rel_error_dx < 1e-7\n",
    "\n",
    "rel_error_dgamma = rel_error(da_num, dgamma)\n",
    "print(f'dgamma error: {rel_error_dgamma}')\n",
    "assert rel_error_dgamma < 1e-10\n",
    "\n",
    "rel_error_dbeta = rel_error(db_num, dbeta)\n",
    "print(f'dbeta error: {rel_error_dbeta}')\n",
    "assert rel_error_dbeta < 1e-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76450a54",
   "metadata": {
    "id": "76450a54"
   },
   "source": [
    "# PART III - Convolutional Neural Networks vs ResNets [28 pts]\n",
    "\n",
    "You can use Google Colab for the rest of the homework.\n",
    "\n",
    "## Environment setup\n",
    "Follow the tutorial about how to utilize Google Colab but **don't install PyTorch** as mentioned in the blog post.\n",
    "\n",
    "English:\n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845d1e5",
   "metadata": {
    "id": "a845d1e5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "# This command should return some information about the GPU status if the runtime is right.\n",
    "# In addition to that, if you encounter memory issues, you can diagnose your model by this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1546b",
   "metadata": {
    "id": "00a1546b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9t7ukBZcxyQH",
   "metadata": {
    "id": "9t7ukBZcxyQH"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e47a6",
   "metadata": {
    "id": "e70e47a6"
   },
   "outputs": [],
   "source": [
    "def fetch_dataloader():\n",
    "    # using random crops and horizontal flip for train set\n",
    "    train_transformer = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "    # transformer for dev set\n",
    "    dev_transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "    # ************************************************************************************\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=True,\n",
    "                                                download=True, transform=train_transformer)\n",
    "    devset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=False,\n",
    "                                              download=True, transform=dev_transformer)\n",
    "\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "\n",
    "    devloader = torch.utils.data.DataLoader(devset, batch_size=64,\n",
    "                                            shuffle=False, num_workers=0)\n",
    "    \n",
    "    return trainloader, devloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7be000",
   "metadata": {
    "id": "ec7be000"
   },
   "source": [
    "### Implement a Deep Neural Network with Convolutional Neural Network Architectures [4 pts]\n",
    "\n",
    "Use Convolutional Neural Network, Linear and Activation Layers to design a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4ae7d",
   "metadata": {
    "id": "6ce4ae7d"
   },
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implement a Convolutional Neural Network with (at least two) convolutional, linear and activation layers you have implemented\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Implement architecture\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        # YOUR CODE STARTS\n",
    "\n",
    "\n",
    "        # YOUR CODE ENDS\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implement forward-pass\n",
    "        \"\"\"\n",
    "\n",
    "         # YOUR CODE STARTS\n",
    "\n",
    "\n",
    "        # YOUR CODE ENDS\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3b0a9",
   "metadata": {
    "id": "ec7be000"
   },
   "source": [
    "### Implement a ResNet with residual blocks [4 pts]\n",
    "\n",
    "Residual Networks introduce skip connections to improve training dynamics. First, implement a simplified ResNet block. Then, use three residual blocks to build a small ResNet. Use layers you implemented above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2767f0a",
   "metadata": {
    "id": "6ce4ae7d"
   },
   "outputs": [],
   "source": [
    "class customResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Implement architecture\n",
    "        \"\"\"\n",
    "        super(customResNet, self).__init__()\n",
    "                \n",
    "        self.conv1 = ## TODO ##\n",
    "        self.bn1 = ## TODO ##\n",
    "        self.AvgPool2d = ## TODO ##\n",
    "        self.relu = ## TODO ##\n",
    "        \n",
    "        self.layer1 = self.make_block(64, stride=1)\n",
    "        self.layer2 = self.make_block(128, stride=2)\n",
    "        self.layer3 = self.make_block(256, stride=2)\n",
    "        self.linear = ## TODO ##\n",
    "\n",
    "        \n",
    "    def make_block(self, ch=64, stride=2)\n",
    "    \n",
    "        # YOUR CODE STARTS\n",
    "\n",
    "        # YOUR CODE ENDS    \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.AvgPool2d(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77caa4",
   "metadata": {
    "id": "fc77caa4"
   },
   "source": [
    "### Initialize your networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c20d1",
   "metadata": {
    "id": "0f3c20d1"
   },
   "outputs": [],
   "source": [
    "networks = {\"CNN\": CNN(), \"customResNet\": customResNet()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51111359",
   "metadata": {
    "id": "51111359"
   },
   "source": [
    "### Initialization of the Optimizers: You can change the Parameters according to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489318db",
   "metadata": {
    "id": "489318db"
   },
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"CNN\": optim.Adam(networks[\"CNN\"].parameters(), lr=1e-3),\n",
    "    \"customResNet\": optim.Adam(networks[\"customResNet\"].parameters(), lr=1e-3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab750e1",
   "metadata": {
    "id": "fab750e1"
   },
   "source": [
    "### Initialization of the losses: You can change the parameters according to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21060791",
   "metadata": {
    "id": "21060791"
   },
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"CNN\": torch.nn.CrossEntropyLoss(reduction='sum'),\n",
    "    \"customResNet\": torch.nn.CrossEntropyLoss(reduction='sum'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vey4sQDntKgN",
   "metadata": {
    "id": "Vey4sQDntKgN"
   },
   "source": [
    "### Setting the training length: You can change the parameters according to your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oRtAeeoYtKgN",
   "metadata": {
    "id": "oRtAeeoYtKgN"
   },
   "outputs": [],
   "source": [
    "epochs = {\n",
    "    \"CNN\": 15,\n",
    "    \"customResNet\": 15\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee9e64",
   "metadata": {
    "id": "d5ee9e64"
   },
   "source": [
    "### Training Loop [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56487d",
   "metadata": {
    "id": "af56487d"
   },
   "outputs": [],
   "source": [
    "def train(network, optimizer, loss_fn, train_loader, epochs=10, verbose=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Implement training loop\n",
    "    \"\"\"\n",
    "    train_data = None\n",
    "    # YOUR CODE STARTS\n",
    "\n",
    "\n",
    "    # YOUR CODE ENDS\n",
    "    return network, train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32bfc7a",
   "metadata": {
    "id": "d32bfc7a"
   },
   "source": [
    "### Evaluation based on Accuracy [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adec11",
   "metadata": {
    "id": "94adec11"
   },
   "outputs": [],
   "source": [
    "def evalf(network, test_loader, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Implement evaluation for accuracy\n",
    "    \"\"\"\n",
    "    val_data = None\n",
    "\n",
    "    # YOUR CODE STARTS\n",
    "\n",
    "\n",
    "    # YOUR CODE ENDS\n",
    "\n",
    "    return accuracy, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a9bdd",
   "metadata": {
    "id": "238a9bdd"
   },
   "source": [
    "### Combine everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c56101",
   "metadata": {
    "id": "e3c56101"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_data, val_data = {}, {}\n",
    "train_loader, test_loader = fetch_dataloader()\n",
    "\n",
    "for arch in [\"CNN\", \"customResNet\"]:\n",
    "    network, optimizer, loss_fn = networks[arch], optimizers[arch], losses[arch]\n",
    "\n",
    "    network, train_data[arch] = train(network, optimizer, loss_fn, train_loader, epochs=epochs[arch], verbose=False, device=device)\n",
    "    accuracy, val_data[arch] = evalf(network, test_loader, device=device)\n",
    "    \n",
    "    print(f\"for {arch}|\\t Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03e83e",
   "metadata": {},
   "source": [
    "### Visualize The First Two Convolution Layer Filter/Kernels of CNN Model and comment on the apperance of the filters.  [3 pts]\n",
    "Display the filters/kernels in the first and second convolutional layers. You can change below code if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf22608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first two conv layer outputs, filter an example image with first conv filters\n",
    "# Code here\n",
    "conv_layers[0] # First layer conv filters\n",
    "conv_layers[1] # Second layer conv filters\n",
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f1ab1",
   "metadata": {
    "id": "962f1ab1"
   },
   "source": [
    "## Compare the results [9 pts]\n",
    "\n",
    "In this part, you will compare the results of both methods. While answering the questions below, consider the following points:\n",
    "\n",
    "- What are the advantages and disadvantages of these models?\n",
    "- In what scenarios would you use a CNN versus a custom ResNet?\n",
    "- Is early stopping necessary during training? If so, why?\n",
    "    \n",
    "Also, feel free to use any library you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tLZhhnkA3K3M",
   "metadata": {
    "id": "tLZhhnkA3K3M"
   },
   "source": [
    "#### Plot loss and accuracy curves per training epoch for both train and test sets. Make sure you put legend and labels. Comment on the results. [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c260bf",
   "metadata": {
    "id": "99c260bf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "--s20NOl39CN",
   "metadata": {
    "id": "--s20NOl39CN"
   },
   "source": [
    "#### Visualize a few example test outputs with true and predicted labels (both models). Make comments [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mEC0W_4A38yZ",
   "metadata": {
    "id": "mEC0W_4A38yZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qTGZkcf121_L",
   "metadata": {
    "id": "qTGZkcf121_L"
   },
   "source": [
    "#### Compare number of parameters of the models. Comment your insights [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21574b7",
   "metadata": {
    "id": "a21574b7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b913af59",
   "metadata": {},
   "source": [
    "# PART IV Object Detection [28 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1518a49",
   "metadata": {},
   "source": [
    "Object detection is a computer vision task where the goal is to identify and localize objects within an image. \n",
    "Unlike image classification, where the focus is on assigning a single label to an image, object detection involves:\n",
    "- Predicting **what** objects are present (class labels).\n",
    "- Predicting **where** the objects are located (bounding boxes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a4952",
   "metadata": {},
   "source": [
    "#### Image Classification vs Object Detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400820b",
   "metadata": {},
   "source": [
    "Image classification answers the question: **What is in the image?**\n",
    "\n",
    "Object detection answers the questions: **What objects are in the image, and where are they located?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc08b6",
   "metadata": {},
   "source": [
    "#### Why Object Detection?\n",
    "Object detection is used in a variety of real-world applications, such as:\n",
    "- **Autonomous vehicles**: Detecting pedestrians, vehicles, and traffic signs.\n",
    "- **Medical imaging**: Identifying abnormalities in scans (e.g., tumors).\n",
    "- **Surveillance**: Recognizing and tracking people or objects in video feeds.\n",
    "- **Retail**: Counting products or monitoring shelves.\n",
    "\n",
    "\n",
    "#### Components of Object Detection:\n",
    "\n",
    "A basic object detection network typically consists of two outputs:\n",
    "1. **Class Prediction**: A probability distribution over possible object classes.\n",
    "2. **Bounding Box Regression**: Coordinates of the bounding box enclosing the object.\n",
    "\n",
    "\n",
    "- The bounding box is represented as `[x_min, y_min, x_max, y_max]`, where:\n",
    "  - `(x_min, y_min)` is the top-left corner.\n",
    "  - `(x_max, y_max)` is the bottom-right corner.\n",
    "- The network predicts both **what** (class label) and **where** (bounding box coordinates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b3a39",
   "metadata": {},
   "source": [
    "### Define a Basic Object Detection Network\n",
    "The network should:\n",
    "- Take an image as input.\n",
    "- Output a class label and four bounding box coordinates.\n",
    "\n",
    "**Hints**:\n",
    "- The final layer should output both the class probabilities and bounding box coordinates.\n",
    "- Use the CNN you trained in the previous part as the backbone of your object detector. Add two heads to your backbone model, where one of the heads will predict the object class and the other will predict the object location. \n",
    "\n",
    "\n",
    "**Steps**:\n",
    "- Implement a network that consists of a backbone and two heads.\n",
    "- Build forward and backward propagation for the network.\n",
    "- Use separate loss functions for classification (cross-entropy) and bounding box regression (mean squared error).\n",
    "- Train the network on the object detection dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e356e8",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce403cdc",
   "metadata": {},
   "source": [
    "You will detect license plates:\n",
    "https://ieee-dataport.org/open-access/cd-lp-compressed-domain-license-plate-detection-database\n",
    "\n",
    "The dataset contains 2,400 vehicle images for license plate detection purposes. There are 3 subsets, where you'll use only pixel domain images (2400 images). Since you'll predict the license plate coordinates, number of classes will be 2 (plate and non-plate objects). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58653d",
   "metadata": {},
   "source": [
    "#### Implement the network [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5253898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817bb8a",
   "metadata": {},
   "source": [
    "#### Train the network [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edee9d",
   "metadata": {},
   "source": [
    "#### Evaluate the model and plot precision, recall, and mAP scores for different IoU thresholds [5 pts]\n",
    "\n",
    "Evaluate the network using **evaluate()** below for different IoU thresholds [0.1; 0.1; 1]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_iou(pred_box, gt_box):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    Args:\n",
    "        pred_box (list): [x_min, y_min, x_max, y_max] for the predicted box.\n",
    "        gt_box (list): [x_min, y_min, x_max, y_max] for the ground truth box.\n",
    "    Returns:\n",
    "        float: IoU value.\n",
    "    \"\"\"\n",
    "    # Compute intersection\n",
    "    x_min_inter = max(pred_box[0], gt_box[0])\n",
    "    y_min_inter = max(pred_box[1], gt_box[1])\n",
    "    x_max_inter = min(pred_box[2], gt_box[2])\n",
    "    y_max_inter = min(pred_box[3], gt_box[3])\n",
    "\n",
    "    inter_area = max(0, x_max_inter - x_min_inter) * max(0, y_max_inter - y_min_inter)\n",
    "    \n",
    "    # Compute union\n",
    "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "    union_area = pred_area + gt_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def evaluate(predictions, ground_truths, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate object detection metrics: Precision, Recall, and mAP.\n",
    "    Args:\n",
    "        predictions (list): List of predicted bounding boxes [[x_min, y_min, x_max, y_max, class], ...].\n",
    "        ground_truths (list): List of ground truth boxes [[x_min, y_min, x_max, y_max, class], ...].\n",
    "        iou_threshold (float): IoU threshold to consider a prediction correct.\n",
    "    Returns:\n",
    "        dict: Precision, Recall, and mAP scores.\n",
    "    \"\"\"\n",
    "    tp = 0  # True positives\n",
    "    fp = 0  # False positives\n",
    "    fn = 0  # False negatives\n",
    "\n",
    "    matched_gt = set()  # Keep track of matched ground truths\n",
    "\n",
    "    for pred in predictions:\n",
    "        pred_box, pred_class = pred[:4], pred[4]\n",
    "        max_iou = 0\n",
    "        matched = None\n",
    "\n",
    "        for i, gt in enumerate(ground_truths):\n",
    "            gt_box, gt_class = gt[:4], gt[4]\n",
    "\n",
    "            # Only consider matching predictions of the same class\n",
    "            if pred_class == gt_class:\n",
    "                iou = calculate_iou(pred_box, gt_box)\n",
    "                if iou > max_iou and iou >= iou_threshold and i not in matched_gt:\n",
    "                    max_iou = iou\n",
    "                    matched = i\n",
    "\n",
    "        if matched is not None:\n",
    "            tp += 1\n",
    "            matched_gt.add(matched)\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    fn = len(ground_truths) - len(matched_gt)\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "\n",
    "    # For simplicity, mAP can be computed as Precision in this example\n",
    "    # In real scenarios, mAP requires averaging precision at multiple recall thresholds\n",
    "    mAP = precision\n",
    "\n",
    "    return {\"Precision\": precision, \"Recall\": recall, \"mAP\": mAP}\n",
    "\n",
    "# Example data\n",
    "predictions = [\n",
    "    [50, 50, 150, 150, \"car\"],  # [x_min, y_min, x_max, y_max, class]\n",
    "    [30, 30, 120, 120, \"car\"],\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    [40, 40, 140, 140, \"car\"],  # [x_min, y_min, x_max, y_max, class]\n",
    "    [60, 60, 170, 170, \"car\"],\n",
    "]\n",
    "\n",
    "# Evaluate\n",
    "results = evaluate(predictions, ground_truths, iou_threshold=0.5)\n",
    "print(\"Evaluation Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a7b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bed28",
   "metadata": {},
   "source": [
    "### Comparison [8 pts]\n",
    "Try different backbones: the Resnet you trained and an untrained (only initialized) CNN.\n",
    "Do backbones with different architectures affect the object detection performance?\n",
    "\n",
    "Compare the pretrained and untrained backbones: Do pretrained backbones ease object detection, in your experiments? If not, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c739ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and comment here "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "de89bc0403a3685ad3f83983da38b1b3dd7896aeb9dd382d00c94cb25b5a82ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
